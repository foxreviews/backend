# ğŸš€ Plan de mise Ã  l'Ã©chelle - 35k entreprises/jour

## ğŸ“Š Objectif
Traiter **35 000 entreprises par jour** = **1 458/heure** = **24/minute**

---

## âœ… Ce qui est dÃ©jÃ  en place

### Architecture solide
- âœ… PostgreSQL avec index optimisÃ©s (siren, naf_code, ville, etc.)
- âœ… Redis pour cache et broker Celery
- âœ… Celery configurÃ© avec workers + beat + flower
- âœ… Django REST Framework avec pagination
- âœ… ModÃ¨les de donnÃ©es optimisÃ©s (unique_together, indexes)

### FonctionnalitÃ©s prÃªtes
- âœ… Import INSEE avec retry et rate limiting
- âœ… Mapping NAF â†’ SousCategorie
- âœ… CrÃ©ation automatique ProLocalisation
- âœ… TÃ¢ches pÃ©riodiques (dÃ©sactivation sponsorships, rÃ©gÃ©nÃ©ration)

---

## âŒ Ce qui manque (CRITIQUE)

### 1. **Traitement asynchrone**
**ProblÃ¨me:** Import synchrone bloque le processus  
**Solution:**
```bash
# Fichiers crÃ©Ã©s:
- foxreviews/core/tasks_import.py  # TÃ¢ches Celery optimisÃ©es
- config/settings/celery_optimization.py  # Configuration performance

# Ã€ faire:
- Importer la config dans settings/production.py
- DÃ©ployer avec plusieurs workers Celery
```

### 2. **Bulk Operations**
**ProblÃ¨me:** CrÃ©ation d'entreprises une par une  
**Solution:** Utiliser `bulk_create()` (dÃ©jÃ  implÃ©mentÃ© dans tasks_import.py)
```python
# Avant (lent):
for etab in etablissements:
    Entreprise.objects.create(...)  # 35k appels DB

# AprÃ¨s (rapide):
Entreprise.objects.bulk_create(entreprises, batch_size=100)  # 350 appels DB
```

### 3. **File d'attente avec prioritÃ©s**
**ProblÃ¨me:** Toutes les tÃ¢ches dans une seule queue  
**Solution:** SÃ©parer par queues (dÃ©jÃ  configurÃ© dans celery_optimization.py)
```python
CELERY_TASK_ROUTES = {
    'insee_import': {'queue': 'insee_import', 'priority': 9},
    'proloc_creation': {'queue': 'proloc_creation', 'priority': 8},
    'ai_generation': {'queue': 'ai_generation', 'priority': 5},
    'periodic': {'queue': 'periodic', 'priority': 3},
}
```

### 4. **Rate Limiting API**
**ProblÃ¨me:** Risque de dÃ©passer quotas INSEE  
**Solution:** Rate limiting configurÃ© (100 appels/minute max)
```python
@shared_task(rate_limit='100/m')
def import_batch_insee(...):
    ...
```

### 5. **Monitoring & Logs**
**ProblÃ¨me:** Difficile de suivre l'import en temps rÃ©el  
**Solution:** 
- Flower (dÃ©jÃ  configurÃ©) - http://localhost:5558
- Logs structurÃ©s
- Progress tracking

---

## ğŸ¯ Plan d'action immÃ©diat

### Phase 1: Configuration (1 heure)
```bash
# 1. Activer la config optimisÃ©e
echo "from .celery_optimization import *" >> config/settings/production.py

# 2. RedÃ©marrer les services
docker-compose -f docker-compose.local.yml restart
```

### Phase 2: Test Ã  petite Ã©chelle (30 min)
```bash
# Test avec 1000 entreprises
docker-compose -f docker-compose.local.yml exec django python manage.py shell

from foxreviews.core.tasks_import import schedule_daily_insee_import
# Modifier temporairement target=1000 dans la fonction
schedule_daily_insee_import()

# Monitoring
docker-compose -f docker-compose.local.yml exec django \
  celery -A config inspect active_queues
```

### Phase 3: MontÃ©e en charge progressive
```
Jour 1: 1 000 entreprises/jour
Jour 2: 5 000 entreprises/jour
Jour 3: 10 000 entreprises/jour
Jour 4: 20 000 entreprises/jour
Jour 5: 35 000 entreprises/jour âœ…
```

---

## ğŸ“Š Estimation des ressources

### Pour 35k entreprises/jour:

**CPU:**
- Minimum: 4 cores
- RecommandÃ©: 8 cores
- Workers Celery: 8 parallÃ¨les

**RAM:**
- Minimum: 8 GB
- RecommandÃ©: 16 GB
- PostgreSQL: 4 GB
- Redis: 2 GB
- Django + Celery: 8 GB

**Stockage:**
- PostgreSQL: ~500 MB/mois (35k entreprises)
- Logs: ~1 GB/mois
- Total: 10 GB minimum

**RÃ©seau:**
- API INSEE: ~100 requÃªtes/minute
- API IA: ~500 requÃªtes/minute (si gÃ©nÃ©ration activÃ©e)

---

## â±ï¸ Temps estimÃ© d'import

### Avec optimisations:
```
35 000 entreprises Ã· 100 (batch) = 350 batches
350 batches Ã· 8 (workers parallÃ¨les) = 44 batches par worker
44 batches Ã— 10 secondes (appel API + DB) = 440 secondes = ~7 minutes

âœ… Import total: 10-15 minutes avec retry et rate limiting
```

### Sans optimisations (actuel):
```
35 000 entreprises Ã— 2 secondes (appel API sÃ©quentiel) = 70 000 secondes
= 19 heures âŒ INACCEPTABLE
```

---

## ğŸ”§ Configuration Docker-Compose

Ajuster `docker-compose.local.yml`:

```yaml
celeryworker:
  command: celery -A config worker -l info --concurrency=8 -Q insee_import,proloc_creation,ai_generation,periodic
  deploy:
    replicas: 2  # 2 workers pour haute disponibilitÃ©
  resources:
    limits:
      cpus: '4'
      memory: 4G
```

---

## ğŸ“ Commandes utiles

```bash
# Monitoring Flower
http://localhost:5558

# VÃ©rifier les queues
docker-compose -f docker-compose.local.yml exec django \
  celery -A config inspect active_queues

# Stats workers
docker-compose -f docker-compose.local.yml exec django \
  celery -A config inspect stats

# Purger une queue
docker-compose -f docker-compose.local.yml exec django \
  celery -A config purge

# Logs en temps rÃ©el
docker-compose -f docker-compose.local.yml logs -f celeryworker
```

---

## âœ… Checklist avant production

- [ ] Config Celery optimisÃ©e importÃ©e
- [ ] Workers configurÃ©s (8 concurrency, 2 replicas)
- [ ] Queues sÃ©parÃ©es (insee_import, proloc_creation, etc.)
- [ ] Rate limiting activÃ© (100/m pour INSEE)
- [ ] Bulk operations testÃ©es
- [ ] Test 1000 entreprises OK
- [ ] Test 10 000 entreprises OK
- [ ] Monitoring Flower accessible
- [ ] Logs structurÃ©s configurÃ©s
- [ ] Alerting en cas d'erreur (Sentry)
- [ ] Backup PostgreSQL automatique
- [ ] Quotas INSEE vÃ©rifiÃ©s

---

## ğŸ“ˆ Ã‰volution future (>100k/jour)

Si besoin de monter Ã  **100k+ entreprises/jour**:

1. **Horizontal scaling:**
   - Ajouter plus de workers Celery
   - Load balancer pour Django
   - PostgreSQL en cluster (read replicas)

2. **Caching agressif:**
   - Cache Redis pour mappings NAF
   - Cache ProLocalisations
   - CDN pour assets statiques

3. **Base de donnÃ©es:**
   - Partitionnement tables (par dÃ©partement)
   - Index partiels
   - Materialized views

4. **Message Queue:**
   - RabbitMQ au lieu de Redis (plus robuste)
   - Dead letter queue pour erreurs
   - Priority queues

---

## ğŸ¯ Conclusion

**Ã‰tat actuel:** âŒ Non prÃªt (19h pour 35k)  
**Avec optimisations:** âœ… PrÃªt (10-15 min pour 35k)

**Prochaine Ã©tape:** Importer les fichiers de config et tester !
