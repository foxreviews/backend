"""
T√¢ches Celery pour la g√©n√©ration automatique d'avis IA.
Rotation quotidienne pour variation des contenus.
"""

import logging

from celery import shared_task
from django.core.management import call_command

logger = logging.getLogger(__name__)


@shared_task(bind=True, name="core.regenerate_ai_reviews_nightly")
def regenerate_ai_reviews_nightly(self):
    """
    T√¢che nocturne: r√©g√©n√®re les avis IA pour variation quotidienne.
    
    - Sponsoris√©s (PREMIUM): r√©g√©n√©ration prioritaire
    - Organiques (STANDARD): r√©g√©n√©ration des avis > 24h
    
    Planification:
    - Tous les jours √† 2h du matin
    - Voir config/settings/base.py (CELERY_BEAT_SCHEDULE)
    """
    logger.info("üîÑ D√©marrage r√©g√©n√©ration nocturne des avis IA")
    
    try:
        # √âtape 1: Sponsoris√©s (qualit√© PREMIUM)
        logger.info("üéØ R√©g√©n√©ration sponsoris√©s (PREMIUM)")
        call_command(
            "generate_ai_reviews_v2",
            "--sponsored-only",
            "--regenerate-old",
            "--days=1",
            "--batch-size=50",
        )
        
        # √âtape 2: Organiques (STANDARD) - s√©lection al√©atoire
        logger.info("üìä R√©g√©n√©ration organiques (STANDARD)")
        call_command(
            "generate_ai_reviews_v2",
            "--organic-only",
            "--regenerate-old",
            "--days=1",
            "--batch-size=100",
        )
        
        logger.info("‚úÖ R√©g√©n√©ration nocturne termin√©e")
        return {"status": "success", "message": "Avis r√©g√©n√©r√©s avec succ√®s"}
        
    except Exception as e:
        logger.exception("‚ùå Erreur r√©g√©n√©ration nocturne")
        return {"status": "error", "message": str(e)}


@shared_task(bind=True, name="core.generate_missing_ai_reviews")
def generate_missing_ai_reviews(self):
    """
    T√¢che de rattrapage: g√©n√®re les avis manquants.
    Utile apr√®s l'ajout de nouvelles entreprises.
    
    Planification:
    - Tous les jours √† 4h du matin
    """
    logger.info("üîç G√©n√©ration avis manquants")
    
    try:
        call_command(
            "generate_ai_reviews_v2",
            "--batch-size=100",
        )
        
        logger.info("‚úÖ G√©n√©ration avis manquants termin√©e")
        return {"status": "success"}
        
    except Exception as e:
        logger.exception("‚ùå Erreur g√©n√©ration avis manquants")
        return {"status": "error", "message": str(e)}


@shared_task(bind=True, name="core.regenerate_sponsored_premium")
def regenerate_sponsored_premium(self):
    """
    R√©g√©n√®re UNIQUEMENT les sponsoris√©s (qualit√© PREMIUM).
    Force la r√©g√©n√©ration pour garantir la meilleure qualit√©.
    
    Planification:
    - Tous les jours √† 1h du matin
    """
    logger.info("üéØ R√©g√©n√©ration PREMIUM sponsoris√©s")
    
    try:
        call_command(
            "generate_ai_reviews_v2",
            "--sponsored-only",
            "--force",
            "--batch-size=50",
        )
        
        logger.info("‚úÖ R√©g√©n√©ration PREMIUM termin√©e")
        return {"status": "success"}
        
    except Exception as e:
        logger.exception("‚ùå Erreur r√©g√©n√©ration PREMIUM")
        return {"status": "error", "message": str(e)}


@shared_task(
    bind=True,
    name="core.generate_ai_content_for_import",
    autoretry_for=(Exception,),
    retry_kwargs={"max_retries": 2, "countdown": 60},
    soft_time_limit=3600,  # 1 heure
    time_limit=3900,  # 65 minutes
)
def generate_ai_content_for_import(self, import_log_id: int):
    """
    G√©n√®re le contenu IA pour les entit√©s import√©es.
    
    Cette t√¢che est d√©clench√©e apr√®s un import r√©ussi si l'option
    'generate_ai_content' est activ√©e, ou manuellement via l'admin.
    
    Selon le type d'import:
    - ENTREPRISE: g√©n√®re des avis IA pour les nouvelles entreprises
    - SOUS_CATEGORIE: g√©n√®re des descriptions IA pour les sous-cat√©gories
    - CATEGORIE: g√©n√®re des descriptions IA pour les cat√©gories
    
    Args:
        import_log_id: ID de l'ImportLog concern√©
    """
    from foxreviews.core.models_import import ImportLog
    
    logger.info(f"ü§ñ D√©marrage g√©n√©ration IA pour import #{import_log_id}")
    
    try:
        import_log = ImportLog.objects.get(id=import_log_id)
        import_log.ai_generation_started = True
        import_log.save(update_fields=["ai_generation_started"])
        
        if import_log.import_type == ImportLog.ImportType.ENTREPRISE:
            # G√©n√®re des avis IA pour les entreprises import√©es
            logger.info("üìä G√©n√©ration avis IA pour entreprises")
            call_command(
                "generate_ai_reviews_v2",
                "--batch-size=50",
            )
            
        elif import_log.import_type == ImportLog.ImportType.SOUS_CATEGORIE:
            # G√©n√®re des descriptions IA pour les sous-cat√©gories
            logger.info("üìù G√©n√©ration descriptions IA pour sous-cat√©gories")
            # TODO: Ajouter une commande pour g√©n√©rer les descriptions de sous-cat√©gories
            # call_command("generate_subcategory_descriptions")
            
        elif import_log.import_type == ImportLog.ImportType.CATEGORIE:
            # G√©n√®re des descriptions IA pour les cat√©gories
            logger.info("üìù G√©n√©ration descriptions IA pour cat√©gories")
            # TODO: Ajouter une commande pour g√©n√©rer les descriptions de cat√©gories
            # call_command("generate_category_descriptions")
        
        # Marque comme termin√©
        import_log.ai_generation_completed = True
        import_log.save(update_fields=["ai_generation_completed"])
        
        logger.info(f"‚úÖ G√©n√©ration IA termin√©e pour import #{import_log_id}")
        return {"status": "success", "import_log_id": import_log_id}
        
    except ImportLog.DoesNotExist:
        logger.error(f"‚ùå Import #{import_log_id} introuvable")
        return {"status": "error", "message": "Import introuvable"}
        
    except Exception as e:
        logger.exception(f"‚ùå Erreur g√©n√©ration IA pour import #{import_log_id}")
        # Marque l'erreur mais ne bloque pas
        try:
            import_log = ImportLog.objects.get(id=import_log_id)
            import_log.ai_generation_started = False
            import_log.save(update_fields=["ai_generation_started"])
        except Exception:
            pass
        return {"status": "error", "message": str(e)}


@shared_task(
    bind=True,
    name="core.cleanup_old_imports",
    soft_time_limit=600,  # 10 minutes
)
def cleanup_old_imports(self):
    """
    Nettoie les anciens imports et fichiers pour lib√©rer l'espace disque.
    
    - Supprime les ImportLog de plus de 90 jours
    - Supprime les fichiers upload√©s de plus de 30 jours
    - Archive les logs d'erreurs importants
    
    Planification: Tous les dimanches √† 3h du matin
    """
    from datetime import timedelta
    from django.utils import timezone
    from foxreviews.core.models_import import ImportLog
    
    logger.info("üßπ D√©marrage nettoyage des anciens imports")
    
    try:
        now = timezone.now()
        
        # Supprime les imports de plus de 90 jours
        old_date = now - timedelta(days=90)
        old_imports = ImportLog.objects.filter(created_at__lt=old_date)
        count_logs = old_imports.count()
        
        # Supprime les fichiers upload√©s de plus de 30 jours
        file_cleanup_date = now - timedelta(days=30)
        old_files = ImportLog.objects.filter(
            created_at__lt=file_cleanup_date,
            created_at__gte=old_date  # Garde les logs mais supprime les fichiers
        )
        count_files = 0
        for import_log in old_files:
            if import_log.file:
                try:
                    import_log.file.delete(save=False)
                    count_files += 1
                except Exception as e:
                    logger.warning(f"Impossible de supprimer le fichier {import_log.file_name}: {e}")
        
        # Supprime les anciens logs
        old_imports.delete()
        
        logger.info(f"‚úÖ Nettoyage termin√©: {count_logs} logs supprim√©s, {count_files} fichiers supprim√©s")
        return {
            "status": "success",
            "logs_deleted": count_logs,
            "files_deleted": count_files
        }
        
    except Exception as e:
        logger.exception("‚ùå Erreur nettoyage imports")
        return {"status": "error", "message": str(e)}

